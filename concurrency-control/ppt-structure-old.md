# 실무에서 마주친 동시성 문제 해결기
## From Problem to Solution: 스레드와 동시성 제어 Deep Dive

> **발표 컨셉**: "코드 → 문제 → 해결 → 원리 → 실무" 흐름
> **발표 시간**: 35-40분
> **슬라이드 수**: 약 38개

---

## 🎬 발표 구조 Overview

```
Act 1: 문제의 발견 (7분)
    ↓
Act 2: 해결의 과정 (8분)
    ↓
Act 3: 원리의 이해 (15분)
    ↓
Act 4: 실무의 적용 (8분)
    ↓
마무리 (2분)
```

---

# Act 1: 문제의 발견 (7분, 6슬라이드)

## 슬라이드 1: 타이틀
```
실무에서 마주친 동시성 문제 해결기
From Bug to Solution

부제: 1000명이 동시에 좋아요를 누르면 어떻게 될까?

[이름]
[날짜]
```

**발표 멘트:**
```
안녕하세요! 오늘은 제가 실제 프로젝트에서 마주쳤던
동시성 문제와 그 해결 과정을 공유하려고 합니다.

이론보다는 실무 관점에서,
"왜 이게 필요했는지", "어떻게 해결했는지"를 중심으로 말씀드리겠습니다.
```

---

## 슬라이드 2: 평범한 시작
```markdown
# 커뮤니티 서비스 개발 중...

기능: 댓글 좋아요 👍

[코드 스크린샷 또는 간단한 다이어그램]

User → API → Service → Repository → DB

✅ 로컬 테스트: 정상 동작
✅ 단위 테스트: 통과
✅ 배포 완료

"완벽해 보였습니다..."
```

**발표 멘트:**
```
평범한 커뮤니티 서비스를 개발하고 있었습니다.
댓글 좋아요 기능을 만들었고,
로컬에서 테스트도 잘 되고, 단위 테스트도 통과했습니다.

배포하고 나서 "잘 됐다"고 생각했죠.
```

---

## 슬라이드 3: 그런데...
```markdown
# 🔴 부하 테스트 중 이상한 일이...

## 테스트 시나리오
- 1000명의 사용자
- 동시에 같은 댓글에 좋아요 클릭

## 예상 결과
```
좋아요 수: 1000 ✅
```

## 실제 결과
```
좋아요 수: 347 ❌
좋아요 수: 523 ❌
좋아요 수: 681 ❌

매번 다른 숫자!
```

❓ "뭐가 문제지?"
```

**발표 멘트:**
```
그런데 부하 테스트를 돌려보니까...
1000명이 동시에 좋아요를 누르면 1000이 나와야 하는데,
300, 500, 600... 매번 다른 숫자가 나왔습니다.

"뭐가 문제지?" 싶었죠.
```

---

## 슬라이드 4: 문제의 코드
```java
// ❌ 문제가 있는 코드
@Transactional
public void toggleCommentLike(Long commentId, Long userId) {
    // 1. 댓글 조회
    CommunityCommentEntity comment =
        commentRepository.findById(commentId)
            .orElseThrow();

    // 2. 좋아요 수 증가
    comment.incrementLikeCount();  // ⚠️ 여기!

    // 3. 저장
    commentRepository.save(comment);
}
```

**하이라이트:**
- `comment.incrementLikeCount()` 부분을 빨간 박스로 강조
- "여기서 문제 발생!" 화살표

**발표 멘트:**
```
코드를 보면 너무 단순합니다.
1. 댓글 조회하고
2. 좋아요 수 증가하고
3. 저장한다

언뜻 보면 문제가 없어 보이는데...
여기 incrementLikeCount()에서 문제가 발생합니다.
```

---

## 슬라이드 5: 문제 시각화
```markdown
# 동시 실행 시나리오

## Thread 1:
```
1. count 읽기 (0)  ←────┐
2. +1 계산 (1)          │ 동시에!
3. 쓰기 (1)             │
```

## Thread 2:
```
1. count 읽기 (0)  ←────┘
2. +1 계산 (1)
3. 쓰기 (1)
```

## 결과
```
예상: 2
실제: 1  ❌
```

➡️ **Race Condition 발생!**
```

**애니메이션:** 타임라인으로 두 스레드가 동시에 읽는 모습

**발표 멘트:**
```
두 사용자가 동시에 좋아요를 누르면 어떻게 될까요?

Thread 1이 0을 읽고,
Thread 2도 거의 동시에 0을 읽습니다.

둘 다 1을 씁니다.

결과는? 2가 아니라 1입니다!
이게 바로 Race Condition입니다.
```

---

## 슬라이드 6: Act 1 정리
```markdown
# 문제 정리

## 🔍 발견한 것
1. 단일 사용자 환경에서는 문제 없음
2. **동시에 여러 사용자**가 접근하면 문제 발생
3. 데이터 정합성 깨짐

## 🎯 해결해야 할 것
- 여러 스레드가 동시에 같은 데이터를 수정할 때
- 데이터 정합성을 어떻게 보장할 것인가?

## 💡 키워드
**동시성 제어** (Concurrency Control)
```

**발표 멘트:**
```
정리하자면,
단일 사용자는 문제 없는데,
동시에 여러 사용자가 접근하면 데이터가 꼬입니다.

이걸 어떻게 해결할까요?
```

---

# Act 2: 해결의 과정 (8분, 7슬라이드)

## 슬라이드 7: 해결 방법 탐색
```markdown
# 동시성 제어 방법들

## 1️⃣ Application Level
```java
synchronized void increment() { count++; }
AtomicInteger count;
Lock lock = new ReentrantLock();
```

## 2️⃣ Database Level
```java
// 비관적 락 (Pessimistic Lock)
SELECT ... FOR UPDATE

// 낙관적 락 (Optimistic Lock)
@Version column
```

## 🤔 어떤 걸 선택해야 할까?
```

**발표 멘트:**
```
동시성 제어 방법을 찾아봤습니다.

크게 두 가지 레벨이 있습니다.
1. 애플리케이션 레벨: synchronized, Lock 등
2. 데이터베이스 레벨: DB 락 사용

우리는 DB 데이터의 정합성 문제니까
DB 레벨 해결이 적합해 보입니다.
```

---

## 슬라이드 8: 비관적 락 선택 이유
```markdown
# 왜 비관적 락을 선택했나?

## 낙관적 락 (Optimistic Lock)
```
가정: "충돌 안 날 거야"
방식: Version 체크
실패 시: 재시도 필요
```
👎 좋아요는 충돌이 자주 발생 → 재시도 많음

## 비관적 락 (Pessimistic Lock)
```
가정: "충돌 날 거야"
방식: 미리 락을 걸어버림
실패 시: 대기 후 처리
```
👍 충돌 많은 경우 안정적!

## 우리 상황
- ✅ 인기 댓글은 좋아요가 몰림
- ✅ 충돌 빈번
- ✅ 데이터 정합성 최우선

➡️ **비관적 락 선택!**
```

**발표 멘트:**
```
두 가지 락 방식을 비교했습니다.

낙관적 락은 "충돌 안 날 거야"라고 가정하고,
나중에 충돌 나면 재시도합니다.

비관적 락은 "충돌 날 거야"라고 가정하고,
미리 락을 걸어버립니다.

인기 댓글은 좋아요가 몰리니까
충돌이 많이 발생할 겁니다.
그래서 비관적 락을 선택했습니다.
```

---

## 슬라이드 9: 해결 코드 - Repository
```java
// Repository에 비관적 락 추가
@Repository
public interface CommunityCommentRepository
        extends JpaRepository<CommunityCommentEntity, Long> {

    // ✅ 비관적 락 쿼리 추가
    @Lock(LockModeType.PESSIMISTIC_WRITE)
    @Query("SELECT c FROM CommunityCommentEntity c " +
           "WHERE c.commentId = :commentId")
    Optional<CommunityCommentEntity> findByIdWithPessimisticLock(
        @Param("commentId") Long commentId
    );
}
```

**하이라이트:**
- `@Lock(LockModeType.PESSIMISTIC_WRITE)` 강조
- 어노테이션 하나로 해결!

**발표 멘트:**
```
Repository에 새로운 메서드를 추가했습니다.
@Lock 어노테이션 하나 추가하면 끝입니다.

이게 SQL로는 어떻게 번역될까요?
```

---

## 슬라이드 10: SQL 번역
```sql
-- JPA가 자동으로 생성하는 SQL

SELECT *
FROM community_comment
WHERE comment_id = ?
FOR UPDATE;  -- ← 이게 핵심!
```

**설명 박스:**
```
FOR UPDATE의 의미:
- 이 행(row)에 배타적 락(Exclusive Lock) 설정
- 트랜잭션이 끝날 때까지 다른 트랜잭션은 대기
- "내가 쓸 테니까 다른 사람은 기다려!"
```

**발표 멘트:**
```
FOR UPDATE라는 SQL 구문이 추가됩니다.

이게 바로 비관적 락의 핵심입니다.
"이 데이터는 내가 쓸 거니까 다른 사람은 기다려!"
라고 DB에게 말하는 거죠.
```

---

## 슬라이드 11: 해결 코드 - Service
```java
// ✅ 비관적 락 적용
@Service
@Transactional
public class CommentLikeService {

    public void toggleCommentLike(Long commentId, Long userId) {
        // 1. 비관적 락으로 댓글 조회
        CommunityCommentEntity comment =
            commentRepository.findByIdWithPessimisticLock(commentId)
                .orElseThrow();

        // 2. 좋아요 토글
        if (existsLike(comment, user)) {
            // 좋아요 취소
            comment.decrementLikeCount();
            deleteLike(comment, user);
        } else {
            // 좋아요 추가
            comment.incrementLikeCount();
            saveLike(comment, user);
        }

        // 3. 트랜잭션 커밋 시 자동 저장 & 락 해제
    }
}
```

**발표 멘트:**
```
Service 코드는 거의 그대로입니다.
findById 대신 findByIdWithPessimisticLock만 사용하면 됩니다.

트랜잭션이 끝나면 자동으로 락이 해제됩니다.
```

---

## 슬라이드 12: 동작 흐름
```markdown
# 비관적 락 동작 흐름

## 시간 순서대로:

### Thread 1:
```
10:00:00.000  락 획득 ✅
10:00:00.000  count = 0 읽기
10:00:00.050  count = 1 쓰기
10:00:00.100  트랜잭션 커밋
10:00:00.100  락 해제 🔓
```

### Thread 2:
```
10:00:00.010  락 획득 시도... ⏳ 대기
10:00:00.010  대기 중...
10:00:00.100  락 획득 ✅
10:00:00.100  count = 1 읽기 (최신값!)
10:00:00.150  count = 2 쓰기
10:00:00.200  트랜잭션 커밋
10:00:00.200  락 해제 🔓
```

## 결과
```
count = 2 ✅ 정확!
```
```

**애니메이션:** 타임라인으로 순차 실행 시각화

**발표 멘트:**
```
이제는 순서대로 처리됩니다.

Thread 1이 먼저 락을 획득하면,
Thread 2는 기다립니다.

Thread 1이 끝나고 락을 해제하면,
Thread 2가 락을 획득하고 최신값을 읽습니다.

완벽하게 순차 처리됩니다!
```

---

## 슬라이드 13: 테스트 & 결과
```markdown
# 동시성 테스트 작성

```java
@Test
void concurrencyTest() throws InterruptedException {
    // Given: 1000개의 동시 요청
    int threadCount = 1000;
    ExecutorService executor = Executors.newFixedThreadPool(32);
    CountDownLatch latch = new CountDownLatch(threadCount);

    // When: 동시에 좋아요 클릭
    for (int i = 0; i < threadCount; i++) {
        executor.submit(() -> {
            service.toggleCommentLike(commentId, userId);
            latch.countDown();
        });
    }
    latch.await();

    // Then: 정확히 1000개
    assertThat(comment.getLikeCount()).isEqualTo(1000);
}
```

## ✅ 테스트 결과
```
Before: 347, 523, 681... ❌
After:  1000, 1000, 1000... ✅

성공!
```
```

**발표 멘트:**
```
동시성 테스트를 작성했습니다.
ExecutorService로 1000개의 스레드를 동시에 실행하고,
CountDownLatch로 모든 스레드가 끝날 때까지 기다립니다.

결과는?
정확히 1000개! 매번 1000개!

문제 해결 완료입니다!
```

---

# Act 3: 원리의 이해 (15분, 13슬라이드)

## 슬라이드 14: 원리 파트 시작
```markdown
# 🤔 그런데...

## 궁금한 점들
1. "동시에 실행된다"는 게 정확히 뭘까?
2. 스레드가 뭐길래 이런 문제가 생기지?
3. 왜 락을 걸면 해결될까?

## 답을 찾으려면...
```
프로세스 → 스레드 → 동시성 → 락
```

## 목표
표면적 해결이 아닌,
**깊은 이해**를 통한 진짜 해결!
```

**발표 멘트:**
```
문제는 해결했는데... 궁금증이 생깁니다.

"동시에 실행된다"는 게 정확히 뭘까?
스레드가 뭐길래 이런 문제가 생기지?

이제부터는 원리를 이해해봅시다.
표면적으로 해결하는 게 아니라,
깊이 이해해야 다음 문제도 해결할 수 있습니다.
```

---

## 슬라이드 15: 프로세스란?
```markdown
# 프로세스 (Process)

## 정의
- 실행 중인 프로그램
- OS가 자원을 할당하는 기본 단위

## 구조
```
┌─────────────────────┐
│    Process A        │
├─────────────────────┤
│  Code  (프로그램)    │
│  Data  (전역변수)    │
│  Heap  (동적 할당)   │
│  Stack (함수 호출)   │
└─────────────────────┘
    ↕ 독립적!
┌─────────────────────┐
│    Process B        │
└─────────────────────┘
```

## 특징
- ✅ 독립된 메모리 공간
- ✅ 다른 프로세스 접근 불가
- ❌ 생성/전환 비용 높음 (무거움)
```

**비유 이미지:** 집(독립된 세대)

**발표 멘트:**
```
먼저 프로세스부터 이해해봅시다.

프로세스는 실행 중인 프로그램입니다.
크롬 브라우저, 카카오톡, 각각이 프로세스죠.

각 프로세스는 독립된 메모리를 가집니다.
집으로 비유하면, 각자의 집을 가진 겁니다.
```

---

## 슬라이드 16: 스레드란?
```markdown
# 스레드 (Thread)

## 정의
- 프로세스 내의 실행 단위
- CPU가 실행하는 가장 작은 단위

## 구조
```
┌─────────────────────────────┐
│       Process               │
├─────────────────────────────┤
│  Code  (공유) 📖            │
│  Data  (공유) 📊            │
│  Heap  (공유) 📦 ⚠️ 여기!   │
├─────────────────────────────┤
│  Thread 1   Thread 2        │
│  Stack      Stack           │
│  (개인방)    (개인방)         │
└─────────────────────────────┘
```

## 특징
- ✅ 같은 프로세스 내 자원 공유
- ✅ 생성/전환 비용 낮음 (가벼움)
- ⚠️ **공유 → 동시성 문제!**
```

**비유 이미지:** 집(프로세스) 안의 세대원(스레드)

**발표 멘트:**
```
스레드는 프로세스 안의 실행 단위입니다.

한 집에 여러 세대원이 사는 것처럼,
한 프로세스에 여러 스레드가 있습니다.

핵심은 "공유"입니다.
같은 집의 거실(Heap)을 함께 씁니다.

바로 이 공유가 동시성 문제의 원인입니다!
```

---

## 슬라이드 17: 왜 스레드를 쓸까?
```markdown
# 스레드의 존재 이유

## ❌ 스레드 1개만 있다면?
```
작업1 → 작업2 → 작업3 → ...
한 번에 하나씩만 처리
```

## ✅ 스레드 N개라면?
```
작업1 ↘
작업2 → 동시에 처리! → 빠름!
작업3 ↗
```

## 실제 예시

### 웹 서버 (Tomcat)
```
Thread 1: User A 요청 처리
Thread 2: User B 요청 처리
Thread 3: User C 요청 처리
...
Thread 200: User 200 요청 처리
```

➡️ 200명을 동시에 처리!

## 결론
**효율성 극대화를 위해 스레드 사용!**
```

**발표 멘트:**
```
왜 스레드를 쓸까요?

스레드가 하나만 있으면
한 번에 한 가지 일만 할 수 있습니다.

웹 서버를 생각해보세요.
사용자 200명이 동시에 접속하면?
스레드 200개로 동시에 처리할 수 있습니다.

효율성 극대화!
이게 스레드를 쓰는 이유입니다.
```

---

## 슬라이드 18: 자바 스레드의 비밀
```markdown
# Java Thread = OS Thread

## 구조
```
Java Application
  Thread t = new Thread()
        ↓ JNI
      JVM
        ↓ System Call
    OS Kernel
  Native Thread 생성
        ↓
  1:1 매핑
```

## 비용
```
생성: ~1ms
메모리: 1MB per thread
컨텍스트 스위칭: 5-10μs
```

## 의미
- Java 스레드 1개 = OS 스레드 1개
- 스레드 생성은 비싸다!
- ➡️ **스레드 풀** 사용!

## Java 21+ Virtual Thread
```
경량 스레드 (수백 bytes)
100만개도 가능!
```
```

**발표 멘트:**
```
자바 스레드는 OS 스레드와 1대1로 매핑됩니다.

new Thread() 하나 만들면
실제로 OS 레벨에서 스레드가 생성됩니다.

생성 비용이 비쌉니다.
시간도 걸리고, 메모리도 1MB씩 먹습니다.

그래서 매번 만들지 않고,
스레드 풀을 사용합니다.

참고로 Java 21부터는 Virtual Thread라는
경량 스레드가 나왔습니다.
```

---

## 슬라이드 19: 동시성 문제의 본질
```markdown
# 동시성 문제 = 공유 자원 경쟁

## 문제의 구조

### 독립 자원 (문제 없음)
```
Thread 1: Stack 1 ✅
Thread 2: Stack 2 ✅
→ 각자의 공간, 간섭 없음
```

### 공유 자원 (문제 발생!)
```
Thread 1 ↘
         Heap (count 변수) ⚠️
Thread 2 ↗
→ 동시 접근, Race Condition!
```

## 두 가지 문제

### 1. 원자성 (Atomicity)
```
count++ 는 3단계:
1. READ  count
2. ADD   +1
3. WRITE count

→ 중간에 끊기면 문제!
```

### 2. 가시성 (Visibility)
```
Thread 1: count = 1 (CPU 캐시)
Thread 2: count = 0 (아직 안 보임)

→ 최신값이 안 보임!
```
```

**발표 멘트:**
```
동시성 문제의 본질은 "공유 자원"입니다.

각자의 Stack은 문제 없습니다.
하지만 Heap은 모두가 공유하니까 문제가 생깁니다.

두 가지 문제가 있습니다.

첫째, 원자성.
count++는 사실 3단계입니다.
읽고, 더하고, 쓰고.
중간에 끊기면 문제가 생깁니다.

둘째, 가시성.
한 스레드가 바꾼 값이
다른 스레드에게 안 보일 수 있습니다.
```

---

## 슬라이드 20: 락이 해결하는 방법
```markdown
# 락(Lock)의 원리

## 락 = "화장실 사용 중" 표지판

```
Thread 1: [락 획득] → 작업 중... → [락 해제]
Thread 2:            [대기...]       [락 획득]
```

## 비관적 락의 동작

### 1. 원자성 보장
```
락 획득
  ↓
READ + ADD + WRITE (중간에 안 끊김!)
  ↓
락 해제
```

### 2. 가시성 보장
```
트랜잭션 커밋 시
→ 모든 변경사항 DB(Main Memory)에 반영
→ 다른 스레드가 최신값 읽기 가능
```

## 결과
✅ 순차 처리로 동시성 문제 해결!
```

**비유 이미지:** 화장실 표지판 "사용 중"

**발표 멘트:**
```
락이 어떻게 해결할까요?

락은 "화장실 사용 중" 표지판과 같습니다.
한 명이 쓰고 있으면 다른 사람은 기다립니다.

첫째, 원자성 보장.
락을 획득한 상태에서는
읽기-더하기-쓰기가 중간에 안 끊깁니다.

둘째, 가시성 보장.
트랜잭션 커밋 시 DB에 반영되니까
다른 스레드가 최신값을 읽을 수 있습니다.

이렇게 동시성 문제가 해결됩니다!
```

---

## 슬라이드 21: 다양한 동시성 제어 방법
```markdown
# 동시성 제어 도구 모음

## Application Level

### synchronized
```java
synchronized void method() {
    count++;  // 한 번에 한 스레드만
}
```
- 👍 간단함
- 👎 성능 오버헤드

### AtomicInteger
```java
AtomicInteger count = new AtomicInteger(0);
count.incrementAndGet();  // Lock-Free!
```
- 👍 빠름 (Lock-Free)
- 👎 단순 작업만 가능

### volatile
```java
volatile boolean flag = false;
```
- 👍 가시성 보장
- 👎 원자성 보장 안 됨

## Database Level

### 비관적 락
```sql
SELECT ... FOR UPDATE
```
- 👍 충돌 많을 때 안정적
- 👎 대기 시간 증가

### 낙관적 락
```java
@Version Long version;
```
- 👍 충돌 적을 때 효율적
- 👎 재시도 필요

## 선택 기준
```
작업 유형 + 충돌 빈도 → 적절한 도구 선택
```
```

**발표 멘트:**
```
동시성 제어 방법은 다양합니다.

Application 레벨:
- synchronized: 간단하지만 느림
- AtomicInteger: 빠르지만 단순 작업만
- volatile: 가시성만 보장

Database 레벨:
- 비관적 락: 충돌 많을 때
- 낙관적 락: 충돌 적을 때

상황에 맞는 도구를 선택하는 게 중요합니다.
```

---

## 슬라이드 22: 성능 비교
```markdown
# 성능 Trade-off

## 벤치마크 결과 (10,000 operations)

| 방법 | 시간 | 정합성 | 비고 |
|------|------|--------|------|
| Lock 없음 | 50ms | ❌ 실패 | Race Condition |
| synchronized | 800ms | ✅ 성공 | 느림 |
| AtomicInteger | 500ms | ✅ 성공 | Lock-Free |
| 비관적 락 | 120ms | ✅ 성공 | DB 부하 |
| 낙관적 락 | 80ms | ✅ 성공 | 재시도 필요 |

## 교훈
```
성능 vs 안전성
→ 상황에 맞는 균형점 찾기!
```

## 우리의 선택
```
충돌 빈번 + 정합성 중요
→ 비관적 락 ✅
```
```

**차트:** 시간 vs 정합성 그래프

**발표 멘트:**
```
성능을 비교해봤습니다.

Lock 없으면 가장 빠르지만 틀립니다.
synchronized는 정확하지만 가장 느립니다.
비관적 락은 중간 정도 성능에 정확합니다.

성능과 안전성은 트레이드오프입니다.
상황에 맞는 균형점을 찾는 게 중요합니다.

우리는 정합성이 최우선이니까
비관적 락을 선택했습니다.
```

---

## 슬라이드 23: 스레드 풀의 필요성
```markdown
# 스레드 풀 (Thread Pool)

## ❌ 매번 생성하면?
```java
// 나쁜 예
for (int i = 0; i < 1000; i++) {
    new Thread(() -> task()).start();
}
```
- 1000개 스레드 생성: ~1초
- 메모리: 1GB
- 컨텍스트 스위칭 폭증

## ✅ 스레드 풀 사용
```java
// 좋은 예
ExecutorService pool = Executors.newFixedThreadPool(20);
for (int i = 0; i < 1000; i++) {
    pool.submit(() -> task());
}
```
- 20개만 생성, 재사용
- 메모리: 20MB
- 효율적!

## Spring Boot에서
```java
@Async
public void asyncMethod() {
    // 자동으로 스레드 풀 사용
}
```
```

**발표 멘트:**
```
실무에서는 스레드를 매번 만들지 않습니다.

1000개를 매번 만들면
시간도 오래 걸리고 메모리도 1GB나 먹습니다.

대신 스레드 풀을 씁니다.
20개 정도만 만들어두고 재사용합니다.

Spring Boot에서는 @Async 어노테이션으로
자동으로 스레드 풀을 사용할 수 있습니다.
```

---

## 슬라이드 24: CPU-Bound vs I/O-Bound
```markdown
# 작업 유형에 따른 전략

## CPU-Bound (계산 많음)
```
예: 이미지 처리, 암호화, 정렬
```
**최적 스레드 수: 코어 수 + 1**
```
4코어 CPU → 5개 스레드
```
이유: CPU를 최대한 활용, 컨텍스트 스위칭 최소화

## I/O-Bound (대기 많음)
```
예: DB 쿼리, HTTP 요청, 파일 읽기
```
**최적 스레드 수: 코어 수 × 10 ~ 100**
```
4코어 CPU → 40~400개 스레드
```
이유: 대기 시간에 다른 스레드 실행 가능

## 우리 서비스 (댓글 좋아요)
```
DB 쿼리 위주 → I/O-Bound
→ 스레드 풀 크기를 크게 설정!
```
```

**발표 멘트:**
```
작업 유형에 따라 전략이 다릅니다.

CPU-Bound는 계산이 많은 작업입니다.
코어 수만큼만 스레드를 만듭니다.
더 만들어봤자 컨텍스트 스위칭만 늘어납니다.

I/O-Bound는 대기가 많은 작업입니다.
DB 쿼리, HTTP 요청 같은 거죠.
대기 시간에 다른 스레드가 일할 수 있으니까
스레드를 많이 만듭니다.

우리 서비스는 DB 쿼리 위주니까
I/O-Bound입니다.
스레드 풀 크기를 크게 설정해야 합니다.
```

---

## 슬라이드 25: 컨텍스트 스위칭 비용
```markdown
# 컨텍스트 스위칭 (Context Switching)

## 개념
```
CPU: [Thread A 실행] → [저장] → [복원] → [Thread B 실행]
```

## 비용
```
직접 비용: 5-10μs (레지스터 저장/복원)
간접 비용: 50-100μs (캐시 미스)
```

## 문제 상황
```
스레드가 너무 많으면?
→ 컨텍스트 스위칭 폭증
→ 오히려 느려짐!
```

## 실험 결과 (4코어 CPU)
```
2 threads:  30ms  (1.6배 빨라짐)
4 threads:  20ms  (2.5배 빨라짐)
8 threads:  25ms  (2배 빨라짐) ← 오히려 느려짐!
16 threads: 30ms  (1.6배 빨라짐) ← 더 느려짐!
```

## 교훈
```
스레드 많다고 빠른 게 아니다!
적절한 수를 찾아야 한다!
```
```

**발표 멘트:**
```
컨텍스트 스위칭도 비용입니다.

CPU가 스레드를 전환할 때마다
현재 상태를 저장하고 다음 상태를 복원합니다.

스레드가 너무 많으면
전환만 계속하느라 오히려 느려집니다.

실험해보니 4코어 CPU에서
8개 스레드부터는 오히려 느려졌습니다.

스레드가 많다고 빠른 게 아닙니다.
적절한 수를 찾는 게 중요합니다.
```

---

## 슬라이드 26: 원리 파트 정리
```markdown
# Act 3 정리: 원리 이해

## 배운 것들

### 1. 프로세스 & 스레드
- 프로세스: 독립된 메모리
- 스레드: 공유 메모리 (→ 동시성 문제)

### 2. 동시성 문제
- 원자성: 연산이 중간에 끊김
- 가시성: 변경사항이 안 보임

### 3. 락의 원리
- 순차 처리로 원자성 보장
- 트랜잭션 커밋으로 가시성 보장

### 4. 실무 고려사항
- 스레드 풀로 생성 비용 절약
- 작업 유형에 맞는 스레드 수 설정
- 컨텍스트 스위칭 비용 고려

## 핵심 메시지
```
표면적 해결이 아닌,
원리를 이해하면
다양한 상황에 대응 가능!
```
```

**발표 멘트:**
```
원리 파트를 정리하겠습니다.

프로세스와 스레드의 차이,
동시성 문제가 왜 발생하는지,
락이 어떻게 해결하는지,
실무에서 고려할 사항들을 배웠습니다.

원리를 이해하면
다양한 상황에 대응할 수 있습니다.
```

---

# Act 4: 실무의 적용 (8분, 8슬라이드)

## 슬라이드 27: 실무 적용 파트 시작
```markdown
# 💼 실무에서는 어떻게 쓸까?

## 지금까지 배운 것
- ✅ 동시성 문제 원리 이해
- ✅ 해결 방법 알기

## 이제부터
```
실제 서비스에서 어떻게 적용하는가?
```

## 다룰 내용
1. 실무 적용 패턴
2. 성능 모니터링
3. 문제 상황별 대응
4. 주의사항
```

**발표 멘트:**
```
원리는 이해했으니
이제 실무 얘기를 해봅시다.

실제 서비스에서는 어떻게 쓸까요?
```

---

## 슬라이드 28: 실무 패턴 1 - 계층형 스레드 풀
```markdown
# Pattern 1: 계층형 스레드 풀

## 문제 상황
```
모든 작업을 하나의 스레드 풀로?
→ 중요한 작업이 밀릴 수 있음!
```

## 해결: 용도별 분리

```java
@Configuration
public class ThreadPoolConfig {

    // 1. API 요청용 (빠른 응답 필요)
    @Bean("apiThreadPool")
    public ThreadPoolTaskExecutor apiPool() {
        executor.setCorePoolSize(50);
        executor.setMaxPoolSize(100);
        executor.setQueueCapacity(200);
        return executor;
    }

    // 2. 백그라운드 작업용 (느려도 됨)
    @Bean("backgroundThreadPool")
    public ThreadPoolTaskExecutor bgPool() {
        executor.setCorePoolSize(10);
        executor.setMaxPoolSize(20);
        executor.setQueueCapacity(1000);
        return executor;
    }
}
```

## 사용
```java
@Async("apiThreadPool")
public void handleApiRequest() { ... }

@Async("backgroundThreadPool")
public void sendEmailBatch() { ... }
```

## 효과
- ✅ 중요 작업 우선순위 보장
- ✅ 리소스 격리
```

**발표 멘트:**
```
실무 첫 번째 패턴입니다.

모든 작업을 하나의 스레드 풀로 처리하면
중요한 작업이 밀릴 수 있습니다.

용도별로 스레드 풀을 분리합니다.
API 요청용, 백그라운드 작업용 등.

이메일 발송이 밀려도
사용자 API는 빠르게 처리됩니다.
```

---

## 슬라이드 29: 실무 패턴 2 - 비동기 처리
```markdown
# Pattern 2: 비동기 처리로 성능 향상

## ❌ 동기 처리
```java
public Order processOrder(Order order) {
    checkStock(order);      // 300ms
    processPayment(order);  // 500ms
    reserveShipping(order); // 200ms

    return order;  // 총 1000ms
}
```

## ✅ 비동기 처리
```java
public CompletableFuture<Order> processOrder(Order order) {
    CompletableFuture<Void> stock =
        CompletableFuture.runAsync(() -> checkStock(order));

    CompletableFuture<Void> payment =
        CompletableFuture.runAsync(() -> processPayment(order));

    CompletableFuture<Void> shipping =
        CompletableFuture.runAsync(() -> reserveShipping(order));

    return CompletableFuture.allOf(stock, payment, shipping)
        .thenApply(v -> order);  // 총 500ms (2배 빨라짐!)
}
```

## 언제 사용?
- 독립적으로 실행 가능한 작업들
- I/O 작업이 많은 경우
- 응답 시간 개선 필요 시
```

**발표 멘트:**
```
두 번째 패턴은 비동기 처리입니다.

동기로 처리하면 순차적으로 실행됩니다.
300ms, 500ms, 200ms... 총 1000ms

비동기로 처리하면 동시에 실행됩니다.
가장 긴 500ms만 기다리면 됩니다.
2배 빨라졌습니다!

독립적인 작업들은 비동기로 처리하세요.
```

---

## 슬라이드 30: 실무 패턴 3 - 배치 처리
```markdown
# Pattern 3: 배치 처리로 DB 부하 감소

## ❌ 개별 처리
```java
// 각 요청마다 DB 저장
for (Task task : tasks) {
    repository.save(task);  // 1000번 쿼리
}
// 10,000개 → 30초
```

## ✅ 배치 처리
```java
// 100개씩 모아서 처리
@Scheduled(fixedRate = 100)
public void processBatch() {
    List<Task> batch = queue.drainTo(100);
    repository.saveAll(batch);  // 1번 쿼리 (Bulk Insert)
}
// 10,000개 → 2초 (15배 빨라짐!)
```

## 적용 사례
- 로그 저장
- 알림 발송
- 통계 집계
- 실시간성이 덜 중요한 작업

## 주의사항
- 배치 크기 조절 (너무 크면 메모리 부담)
- 지연 시간 허용 범위 확인
```

**발표 멘트:**
```
세 번째 패턴은 배치 처리입니다.

요청마다 DB에 저장하면
쿼리가 1000번 날아갑니다.

100개씩 모아서 한 번에 저장하면
쿼리가 10번만 날아갑니다.

로그 저장, 알림 발송 같은
실시간성이 덜 중요한 작업에 적합합니다.

15배 빨라졌습니다!
```

---

## 슬라이드 31: 성능 모니터링
```markdown
# 성능 모니터링 필수!

## 모니터링 지표

### 1. 스레드 풀 상태
```java
ThreadPoolExecutor pool = ...;

- pool.getActiveCount()      // 활성 스레드 수
- pool.getPoolSize()          // 현재 풀 크기
- pool.getQueue().size()      // 대기 중인 작업
- pool.getCompletedTaskCount() // 완료된 작업
```

### 2. 경고 조건
```
✅ Active == Max  → 풀 부족!
✅ Queue > 80%    → 작업 밀림!
✅ Rejected > 0   → 거부 발생!
```

### 3. 실시간 알림
```java
@Scheduled(fixedRate = 5000)
public void checkThreadPool() {
    if (pool.getActiveCount() == pool.getMaximumPoolSize()) {
        alertService.send("스레드 풀 포화!");
    }
}
```

## 도구
- Micrometer + Prometheus + Grafana
- Spring Boot Actuator
- APM (Scouter, Pinpoint)
```

**발표 멘트:**
```
모니터링은 필수입니다!

스레드 풀 상태를 계속 확인해야 합니다.
활성 스레드 수, 대기 중인 작업, 완료된 작업 등.

경고 조건을 설정하세요.
스레드 풀이 가득 차면 알림을 보냅니다.

Grafana 같은 도구로 시각화하면 좋습니다.
```

---

## 슬라이드 32: 문제 상황별 대응
```markdown
# 실무에서 만나는 문제들

## 상황 1: 스레드 풀 포화
```
증상: 응답 시간 급증
원인: 스레드 수 부족
```
**해결:**
- 스레드 풀 크기 증가
- 작업을 경량화
- 비동기 처리 적용

## 상황 2: Deadlock 발생
```
증상: 특정 요청이 멈춤
원인: 순환 대기 (락 순서 문제)
```
**해결:**
- 락 획득 순서 일관성 유지
- Timeout 설정
- jstack으로 Deadlock 감지

## 상황 3: 데이터 정합성 깨짐
```
증상: 숫자가 안 맞음
원인: Race Condition
```
**해결:**
- 적절한 락 사용 (비관적/낙관적)
- AtomicInteger 등 사용
- 동시성 테스트 작성

## 상황 4: 성능 저하
```
증상: 전반적으로 느림
원인: 불필요한 동기화
```
**해결:**
- Lock 범위 최소화
- Lock-Free 자료구조 사용
- ThreadLocal 활용
```

**발표 멘트:**
```
실무에서 만나는 문제 상황들입니다.

스레드 풀 포화는 스레드 수를 늘리거나
작업을 경량화합니다.

Deadlock은 락 순서를 일관되게 유지하고
Timeout을 설정합니다.

데이터 정합성 문제는 락을 사용하고
동시성 테스트를 작성합니다.

성능 저하는 Lock 범위를 최소화하고
Lock-Free 자료구조를 씁니다.
```

---

## 슬라이드 33: 주의사항 & 베스트 프랙티스
```markdown
# ⚠️ 주의사항

## 하지 말아야 할 것

### 1. 무분별한 synchronized
```java
// ❌ 메서드 전체 동기화
public synchronized void processOrder() {
    // 100줄의 코드...
}

// ✅ 필요한 부분만
public void processOrder() {
    // 일반 로직...
    synchronized(this) {
        count++;  // 최소 범위만!
    }
    // 일반 로직...
}
```

### 2. ThreadLocal 누수
```java
// ❌ 정리 안 함
ThreadLocal<Data> cache = ThreadLocal.withInitial(...);

// ✅ 반드시 정리
try {
    Data data = cache.get();
    // 사용...
} finally {
    cache.remove();  // 필수!
}
```

### 3. 스레드 수 무한정 증가
```java
// ❌ 캐시된 스레드 풀 (위험)
Executors.newCachedThreadPool();

// ✅ 제한된 스레드 풀
Executors.newFixedThreadPool(50);
```

## ✅ 베스트 프랙티스

1. **측정하고 최적화**
   - 추측 금지, 항상 측정!

2. **테스트 작성**
   - 동시성 테스트 필수

3. **문서화**
   - @ThreadSafe, @NotThreadSafe 명시

4. **단순하게**
   - 복잡한 최적화보다 명확한 코드
```

**발표 멘트:**
```
주의사항입니다.

무분별하게 synchronized를 쓰지 마세요.
필요한 부분만 동기화합니다.

ThreadLocal은 반드시 정리하세요.
안 그러면 메모리 누수가 생깁니다.

스레드 수가 무한정 증가하지 않도록
제한을 둡니다.

베스트 프랙티스:
측정하고, 테스트하고, 문서화하고, 단순하게!
```

---

## 슬라이드 34: 실무 체크리스트
```markdown
# 실무 체크리스트 ✅

## 설계 단계
- [ ] 공유 자원 명확히 파악했는가?
- [ ] 동시성 문제 가능성 검토했는가?
- [ ] 적절한 동시성 제어 방법 선택했는가?
- [ ] 스레드 풀 크기 계산했는가?

## 구현 단계
- [ ] Lock 범위를 최소화했는가?
- [ ] Deadlock 가능성 검토했는가?
- [ ] ThreadLocal 정리 코드 작성했는가?
- [ ] 예외 처리는 적절한가?

## 테스트 단계
- [ ] 동시성 테스트 작성했는가?
- [ ] 부하 테스트 수행했는가?
- [ ] 성능 프로파일링 했는가?
- [ ] 모니터링 지표 설정했는가?

## 운영 단계
- [ ] 스레드 풀 모니터링 중인가?
- [ ] 알림 설정은 적절한가?
- [ ] 로그는 충분한가?
- [ ] 문제 발생 시 대응 방안 있는가?

## 문서화
- [ ] 스레드 안전성 명시했는가?
- [ ] 설정값 근거 문서화했는가?
- [ ] 트러블슈팅 가이드 작성했는가?
```

**발표 멘트:**
```
실무 체크리스트입니다.

설계, 구현, 테스트, 운영, 문서화
각 단계마다 확인할 사항들입니다.

이 체크리스트를 따르면
대부분의 동시성 문제를 예방할 수 있습니다.
```

---

## 슬라이드 35: 실무 적용 사례 요약
```markdown
# 실무 적용 핵심 정리

## 기본 원칙
```
1. 측정할 수 없으면 개선할 수 없다
2. 조기 최적화는 악의 근원
3. 단순함이 최고의 최적화
4. 테스트로 검증하라
```

## 적용 패턴
```
계층형 스레드 풀: 작업 격리
비동기 처리: 응답 시간 개선
배치 처리: DB 부하 감소
```

## 모니터링
```
스레드 풀 상태 실시간 확인
경고 조건 설정
문제 발생 시 빠른 대응
```

## 문제 해결
```
Deadlock → 락 순서 일관성
Race Condition → 적절한 락
성능 저하 → Lock 범위 최소화
```

## 핵심 메시지
```
💡 동시성 제어는 선택이 아닌 필수!
💡 원리를 이해하면 응용 가능!
💡 실무에서는 균형이 중요!
```
```

**발표 멘트:**
```
실무 파트를 정리하겠습니다.

기본 원칙: 측정하고, 단순하게, 테스트하라

적용 패턴: 계층형 스레드 풀, 비동기, 배치

모니터링: 실시간 확인, 경고, 빠른 대응

문제 해결: 각 상황에 맞는 대응

핵심은 원리를 이해하고
상황에 맞는 균형을 찾는 것입니다!
```

---

# 마무리 (2분, 3슬라이드)

## 슬라이드 36: 전체 여정 요약
```markdown
# 우리가 걸어온 길

## Act 1: 문제의 발견
```
평범한 코드 → 동시성 문제 발생
→ Race Condition 발견
```

## Act 2: 해결의 과정
```
비관적 락 선택 → 코드 적용 → 테스트
→ 1000개 정확히 처리 성공!
```

## Act 3: 원리의 이해
```
프로세스 & 스레드 → 동시성 문제 본질
→ 락의 원리 → 실무 고려사항
```

## Act 4: 실무의 적용
```
실무 패턴 → 모니터링 → 문제 해결
→ 체크리스트 & 베스트 프랙티스
```

## 핵심 교훈
```
단순한 버그 픽스가 아니라
깊은 이해를 통한 진정한 성장!
```
```

**발표 멘트:**
```
우리가 걸어온 길을 돌아봅시다.

문제를 발견하고,
해결 방법을 찾고,
원리를 이해하고,
실무에 적용하는 법을 배웠습니다.

단순히 버그를 고친 게 아니라
깊이 이해하며 성장했습니다.
```

---

## 슬라이드 37: 마무리 메시지
```markdown
# 여러분에게 전하고 싶은 말

## 💡 실무의 가치
```
이론은 책으로 배울 수 있지만,
실무 경험은 직접 부딪혀야 얻을 수 있습니다.
```

## 🚀 계속 배우기
```
오늘 배운 것은 시작일 뿐,
더 깊이 공부하고 싶다면:

책: "Java Concurrency in Practice"
공식 문서: Java Tutorials - Concurrency
실습: 직접 동시성 버그 만들고 해결하기
```

## 🎯 핵심 메시지
```
"문제를 만나는 것은 기회다.
그 문제를 깊이 이해하면,
더 나은 개발자가 된다."
```

## 💬 질문 있으신가요?
```
궁금한 점, 의견, 공유하고 싶은 경험 등
모두 환영합니다!
```
```

**발표 멘트:**
```
마지막으로 전하고 싶은 말입니다.

실무에서 만난 문제는 기회입니다.
그 문제를 깊이 이해하면
더 나은 개발자가 됩니다.

오늘 배운 것은 시작일 뿐입니다.
더 깊이 공부해보세요.

이제 질문받겠습니다!
```

---

## 슬라이드 38: 감사 & 연락처
```markdown
# 감사합니다! 🙏

## 발표 자료
```
GitHub: [레포지토리 링크]
블로그: [블로그 링크]
```

## 연락처
```
Email: [이메일]
LinkedIn: [링크]
```

## 참고 자료
```
1. Java Concurrency in Practice - Brian Goetz
2. 발표에 사용한 모든 코드: GitHub 참조
3. 동시성 테스트 예제: 레포지토리 참조
```

## 다시 한번 감사합니다!
```
질문이나 피드백은 언제든 환영합니다.
함께 성장하는 개발자가 되길 바랍니다! 🚀
```
```

**발표 멘트:**
```
발표를 들어주셔서 감사합니다!

발표 자료와 코드는 GitHub에 올려뒀습니다.
필요하신 분들은 참고하세요.

질문이나 피드백은 언제든 환영합니다.
함께 성장하는 개발자가 되길 바랍니다!

감사합니다!
```

---

# 📊 슬라이드 디자인 가이드

## 색상 테마
```
주 색상: #2C3E50 (다크 블루) - 전문적
강조 색상: #E74C3C (빨강) - 문제, 주의
성공 색상: #27AE60 (녹색) - 해결, 성공
정보 색상: #3498DB (파랑) - 정보, 팁
```

## 폰트
```
제목: Pretendard Bold, 36pt
본문: Pretendard Regular, 20pt
코드: Fira Code, 16pt
```

## 레이아웃
```
여백: 충분히 (답답하지 않게)
정렬: 왼쪽 정렬 (가독성)
이미지: 최대 50% (텍스트와 균형)
코드: Syntax Highlighting 필수
```

## 애니메이션
```
최소한으로: 과하지 않게
의미있게: 이해를 돕기 위해
자연스럽게: Fade, Slide 정도만
```

---

# 🎤 발표 팁

## 시간 배분
```
Act 1 (문제): 7분 - 흥미 유발
Act 2 (해결): 8분 - 구체적 솔루션
Act 3 (원리): 15분 - 핵심 내용
Act 4 (실무): 8분 - 실용적 가치
마무리: 2분 - 메시지 전달
총: 40분
```

## 발표 스타일
```
✅ 스토리텔링: 이야기처럼 풀어나가기
✅ 구체적: 추상적 개념보다 실제 예시
✅ 질문 던지기: 청중 참여 유도
✅ 적절한 속도: 너무 빠르지 않게
✅ 눈 맞추기: 청중과 소통
```

## 위기 대응
```
질문 못 들었을 때: "다시 한번 말씀해주시겠어요?"
대답 모를 때: "좋은 질문이네요. 저도 더 알아봐야겠습니다."
시간 부족: Act 3의 일부 슬라이드 빠르게 넘기기
실수 했을 때: 당황하지 말고 웃으며 정정
```

---

# 🎯 발표 목표 달성 기준

## 청중이 가져가야 할 것

### 기본 (모든 청중)
- [ ] 동시성 문제가 무엇인지 안다
- [ ] 왜 발생하는지 이해한다
- [ ] 어떻게 해결하는지 안다

### 중급 (개발 경험자)
- [ ] 비관적 락과 낙관적 락을 구분한다
- [ ] 스레드 풀의 필요성을 안다
- [ ] 실무에서 어떻게 적용할지 감을 잡는다

### 고급 (관심 있는 분)
- [ ] 스레드와 프로세스의 차이를 설명할 수 있다
- [ ] 원자성과 가시성 문제를 이해한다
- [ ] 상황별 적절한 동시성 제어 방법을 선택할 수 있다

## 발표 성공 지표
```
✅ 질문이 나온다 (관심 있다는 증거)
✅ "이해했다"는 반응 (끄덕임, 질문)
✅ 시간 내 완료 (40분 ±5분)
✅ 자신감 있게 발표 (떨지 않음)
✅ 재미있게 들었다는 피드백
```

---

**이 구조로 PPT를 만들면 실무 중심의 깊이 있는 발표가 될 것입니다!**

**Good Luck! 🚀**
