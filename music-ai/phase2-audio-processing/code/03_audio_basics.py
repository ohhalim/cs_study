"""
Phase 2 - Audio Basics
librosaë¥¼ ì‚¬ìš©í•œ ì˜¤ë””ì˜¤ ì²˜ë¦¬ ë° íŠ¹ì§• ì¶”ì¶œ
"""

import librosa
import librosa.display
import numpy as np
import matplotlib.pyplot as plt
import soundfile as sf


def create_sample_audio():
    """ìƒ˜í”Œ ì˜¤ë””ì˜¤ ìƒì„± (C major chord)"""
    print("ğŸµ Creating sample audio (C major chord)")
    print("=" * 50)

    sr = 22050  # ìƒ˜í”Œë§ ë ˆì´íŠ¸
    duration = 2.0  # 2ì´ˆ

    # C major chord: C4(262Hz), E4(330Hz), G4(392Hz)
    t = np.linspace(0, duration, int(sr * duration))

    # 3ê°œ ì‚¬ì¸íŒŒ í•©ì„±
    c4 = 0.3 * np.sin(2 * np.pi * 262 * t)
    e4 = 0.3 * np.sin(2 * np.pi * 330 * t)
    g4 = 0.3 * np.sin(2 * np.pi * 392 * t)

    chord = c4 + e4 + g4

    # ì €ì¥
    sf.write('sample_c_major_chord.wav', chord, sr)
    print(f"âœ… Created: sample_c_major_chord.wav")
    print(f"   Duration: {duration} seconds")
    print(f"   Sample rate: {sr} Hz")
    print()

    return chord, sr


def load_and_analyze_audio(audio_path):
    """ì˜¤ë””ì˜¤ íŒŒì¼ ë¡œë“œ ë° ê¸°ë³¸ ë¶„ì„"""
    print(f"\n{'='*50}")
    print(f"Loading: {audio_path}")
    print(f"{'='*50}\n")

    # ì˜¤ë””ì˜¤ ë¡œë“œ
    y, sr = librosa.load(audio_path, sr=None)  # sr=None: ì›ë³¸ ìƒ˜í”Œë§ ë ˆì´íŠ¸ ìœ ì§€

    print("ğŸ“Š Basic Information:")
    print(f"   Sample rate: {sr} Hz")
    print(f"   Duration: {len(y) / sr:.2f} seconds")
    print(f"   Samples: {len(y):,}")
    print(f"   Channels: Mono")
    print(f"   Data type: {y.dtype}")
    print(f"   Min value: {y.min():.4f}")
    print(f"   Max value: {y.max():.4f}")
    print(f"   Mean: {y.mean():.4f}")
    print()

    return y, sr


def visualize_waveform(y, sr, output_path='waveform.png'):
    """Waveform ì‹œê°í™”"""
    print(f"ğŸ¨ Visualizing waveform")
    print("=" * 50)

    plt.figure(figsize=(14, 4))

    # Time axis
    time = np.arange(len(y)) / sr

    plt.plot(time, y, linewidth=0.5)
    plt.xlabel('Time (seconds)', fontsize=12)
    plt.ylabel('Amplitude', fontsize=12)
    plt.title('Waveform', fontsize=14, fontweight='bold')
    plt.grid(True, alpha=0.3)
    plt.tight_layout()
    plt.savefig(output_path, dpi=150)

    print(f"âœ… Saved: {output_path}")
    print()


def compute_spectrogram(y, sr):
    """Spectrogram ê³„ì‚°"""
    print(f"\n{'='*50}")
    print("Computing Spectrogram")
    print(f"{'='*50}\n")

    # STFT (Short-Time Fourier Transform)
    D = librosa.stft(y)
    S_db = librosa.amplitude_to_db(np.abs(D), ref=np.max)

    print(f"ğŸ“Š Spectrogram:")
    print(f"   Shape: {S_db.shape}")
    print(f"   (Frequency bins x Time frames)")
    print(f"   Frequency bins: {S_db.shape[0]}")
    print(f"   Time frames: {S_db.shape[1]}")
    print()

    # ì‹œê°í™”
    plt.figure(figsize=(14, 6))
    librosa.display.specshow(S_db, sr=sr, x_axis='time', y_axis='hz', cmap='magma')
    plt.colorbar(format='%+2.0f dB')
    plt.xlabel('Time (seconds)', fontsize=12)
    plt.ylabel('Frequency (Hz)', fontsize=12)
    plt.title('Spectrogram', fontsize=14, fontweight='bold')
    plt.tight_layout()
    plt.savefig('spectrogram.png', dpi=150)

    print(f"âœ… Saved: spectrogram.png")
    print()

    return S_db


def compute_mel_spectrogram(y, sr):
    """Mel-spectrogram ê³„ì‚° (ìŒì•… ìƒì„± AIì˜ í•µì‹¬)"""
    print(f"\n{'='*50}")
    print("Computing Mel-Spectrogram")
    print(f"{'='*50}\n")

    # Mel-spectrogram
    mel_spec = librosa.feature.melspectrogram(y=y, sr=sr, n_mels=128)
    mel_db = librosa.power_to_db(mel_spec, ref=np.max)

    print(f"ğŸ“Š Mel-Spectrogram:")
    print(f"   Shape: {mel_db.shape}")
    print(f"   (Mel bins x Time frames)")
    print(f"   Mel bins: {mel_db.shape[0]} (perceptually scaled)")
    print(f"   Time frames: {mel_db.shape[1]}")
    print()

    # ì‹œê°í™”
    plt.figure(figsize=(14, 6))
    librosa.display.specshow(mel_db, sr=sr, x_axis='time', y_axis='mel', cmap='viridis')
    plt.colorbar(format='%+2.0f dB')
    plt.xlabel('Time (seconds)', fontsize=12)
    plt.ylabel('Mel Frequency', fontsize=12)
    plt.title('Mel-Spectrogram (128 bins)', fontsize=14, fontweight='bold')
    plt.tight_layout()
    plt.savefig('mel_spectrogram.png', dpi=150)

    print(f"âœ… Saved: mel_spectrogram.png")
    print()

    print("ğŸ’¡ Why Mel-scale?")
    print("   - ì¸ê°„ ì²­ê°ì€ ì„ í˜•ì´ ì•„ë‹˜ (ë‚®ì€ ì£¼íŒŒìˆ˜ì— ë¯¼ê°)")
    print("   - Mel scale: 1000Hz ì´í•˜ëŠ” ì„ í˜•, ì´ìƒì€ ë¡œê·¸")
    print("   - ìŒì•… ìƒì„± ëª¨ë¸ (MusicGen ë“±)ì€ Mel-spectrogram ì‚¬ìš©")
    print()

    return mel_db


def compute_mfcc(y, sr):
    """MFCC (Mel-Frequency Cepstral Coefficients) ê³„ì‚°"""
    print(f"\n{'='*50}")
    print("Computing MFCC")
    print(f"{'='*50}\n")

    # MFCC
    mfcc = librosa.feature.mfcc(y=y, sr=sr, n_mfcc=20)

    print(f"ğŸ“Š MFCC:")
    print(f"   Shape: {mfcc.shape}")
    print(f"   (20 MFCC coefficients x Time frames)")
    print()

    # ì‹œê°í™”
    plt.figure(figsize=(14, 6))
    librosa.display.specshow(mfcc, sr=sr, x_axis='time', cmap='coolwarm')
    plt.colorbar()
    plt.xlabel('Time (seconds)', fontsize=12)
    plt.ylabel('MFCC Coefficients', fontsize=12)
    plt.title('MFCC (20 coefficients)', fontsize=14, fontweight='bold')
    plt.tight_layout()
    plt.savefig('mfcc.png', dpi=150)

    print(f"âœ… Saved: mfcc.png")
    print()

    print("ğŸ’¡ MFCC vs Mel-spectrogram:")
    print("   - MFCC: ìŒì„± ì¸ì‹ì— ì£¼ë¡œ ì‚¬ìš© (ì••ì¶•ëœ í‘œí˜„)")
    print("   - Mel-spec: ìŒì•… ìƒì„±ì— ì£¼ë¡œ ì‚¬ìš© (ë” ë§ì€ ì •ë³´)")
    print()

    return mfcc


def compute_chroma(y, sr):
    """Chroma features (í™”ìŒ ë¶„ì„)"""
    print(f"\n{'='*50}")
    print("Computing Chroma Features")
    print(f"{'='*50}\n")

    # Chroma
    chroma = librosa.feature.chroma_stft(y=y, sr=sr)

    print(f"ğŸ“Š Chroma:")
    print(f"   Shape: {chroma.shape}")
    print(f"   (12 pitch classes x Time frames)")
    print(f"   Pitch classes: C, C#, D, D#, E, F, F#, G, G#, A, A#, B")
    print()

    # ì‹œê°í™”
    plt.figure(figsize=(14, 6))
    librosa.display.specshow(chroma, sr=sr, x_axis='time', y_axis='chroma', cmap='plasma')
    plt.colorbar()
    plt.xlabel('Time (seconds)', fontsize=12)
    plt.ylabel('Pitch Class', fontsize=12)
    plt.title('Chroma Features', fontsize=14, fontweight='bold')
    plt.tight_layout()
    plt.savefig('chroma.png', dpi=150)

    print(f"âœ… Saved: chroma.png")
    print()

    print("ğŸ’¡ Chroma Features:")
    print("   - ì˜¥íƒ€ë¸Œ ë¬´ê´€ (C4ì™€ C5ëŠ” ê°™ì€ C)")
    print("   - í™”ìŒ ë¶„ì„ì— ìœ ìš©")
    print("   - Charlie Parkerì˜ ì½”ë“œ ì§„í–‰ ë¶„ì„ ê°€ëŠ¥")
    print()

    return chroma


def compute_tempo_and_beat(y, sr):
    """í…œí¬ ë° ë¹„íŠ¸ ì¶”ì •"""
    print(f"\n{'='*50}")
    print("Computing Tempo and Beats")
    print(f"{'='*50}\n")

    # í…œí¬ ì¶”ì •
    tempo, beats = librosa.beat.beat_track(y=y, sr=sr)

    print(f"ğŸ“Š Tempo:")
    print(f"   BPM: {tempo:.1f}")
    print(f"   Beats detected: {len(beats)}")
    print(f"   Beat frames: {beats[:10]}... (first 10)")
    print()

    # ë¹„íŠ¸ ì‹œê°„ ë³€í™˜
    beat_times = librosa.frames_to_time(beats, sr=sr)
    print(f"   Beat times (sec): {beat_times[:10]}... (first 10)")
    print()

    return tempo, beat_times


def pitch_shift_example(y, sr):
    """Pitch shifting (ë°ì´í„° ì¦ê°•)"""
    print(f"\n{'='*50}")
    print("Pitch Shifting Example")
    print(f"{'='*50}\n")

    # +2 semitones (í•œ ìŒ ì˜¬ë¦¼)
    y_shifted_up = librosa.effects.pitch_shift(y, sr=sr, n_steps=2)

    # -3 semitones
    y_shifted_down = librosa.effects.pitch_shift(y, sr=sr, n_steps=-3)

    # ì €ì¥
    sf.write('shifted_up_2.wav', y_shifted_up, sr)
    sf.write('shifted_down_3.wav', y_shifted_down, sr)

    print(f"âœ… Created:")
    print(f"   - shifted_up_2.wav (+2 semitones)")
    print(f"   - shifted_down_3.wav (-3 semitones)")
    print()

    print("ğŸ’¡ Data Augmentation:")
    print("   - Pitch shiftingìœ¼ë¡œ ë°ì´í„° ì¦ê°•")
    print("   - Charlie Parker ì†”ë¡œë¥¼ ì—¬ëŸ¬ í‚¤ë¡œ ë³€í™˜")
    print("   - í•™ìŠµ ë°ì´í„° 10ë°° í™•ì¥ ê°€ëŠ¥")
    print()


def time_stretch_example(y, sr):
    """Time stretching (í…œí¬ ë³€ê²½)"""
    print(f"\n{'='*50}")
    print("Time Stretching Example")
    print(f"{'='*50}\n")

    # 1.2ë°° ë¹ ë¥´ê²Œ
    y_faster = librosa.effects.time_stretch(y, rate=1.2)

    # 0.8ë°° ëŠë¦¬ê²Œ
    y_slower = librosa.effects.time_stretch(y, rate=0.8)

    # ì €ì¥
    sf.write('faster_1.2x.wav', y_faster, sr)
    sf.write('slower_0.8x.wav', y_slower, sr)

    print(f"âœ… Created:")
    print(f"   - faster_1.2x.wav (1.2x speed)")
    print(f"   - slower_0.8x.wav (0.8x speed)")
    print()

    print("ğŸ’¡ Time Stretching:")
    print("   - í”¼ì¹˜ ë³€í™” ì—†ì´ í…œí¬ë§Œ ë³€ê²½")
    print("   - ì¬ì¦ˆ ì—°ìŠµ: ëŠë¦° í…œí¬ë¡œ ë¨¼ì € í•™ìŠµ")
    print()


def main():
    """ì „ì²´ ì˜¤ë””ì˜¤ ì²˜ë¦¬ íŒŒì´í”„ë¼ì¸"""
    print("\n" + "ğŸµ" * 25)
    print(" " * 15 + "Audio Processing Tutorial")
    print("ğŸµ" * 25 + "\n")

    # 1. ìƒ˜í”Œ ì˜¤ë””ì˜¤ ìƒì„±
    print("ğŸ“ Step 1: Create Sample Audio")
    y_sample, sr_sample = create_sample_audio()

    # 2. ì˜¤ë””ì˜¤ ë¡œë“œ
    print("ğŸ“– Step 2: Load Audio")
    y, sr = load_and_analyze_audio('sample_c_major_chord.wav')

    # 3. Waveform ì‹œê°í™”
    print("ğŸ¨ Step 3: Visualize Waveform")
    visualize_waveform(y, sr)

    # 4. Spectrogram
    print("ğŸ” Step 4: Spectrogram")
    S_db = compute_spectrogram(y, sr)

    # 5. Mel-spectrogram (ì¤‘ìš”!)
    print("ğŸŒŸ Step 5: Mel-Spectrogram (Key for Music AI)")
    mel_db = compute_mel_spectrogram(y, sr)

    # 6. MFCC
    print("ğŸ“Š Step 6: MFCC")
    mfcc = compute_mfcc(y, sr)

    # 7. Chroma
    print("ğŸ¼ Step 7: Chroma Features")
    chroma = compute_chroma(y, sr)

    # 8. Tempo & Beat
    print("â±ï¸ Step 8: Tempo and Beat")
    tempo, beats = compute_tempo_and_beat(y, sr)

    # 9. Pitch shifting
    print("ğŸšï¸ Step 9: Pitch Shifting")
    pitch_shift_example(y, sr)

    # 10. Time stretching
    print("â© Step 10: Time Stretching")
    time_stretch_example(y, sr)

    # ìš”ì•½
    print("=" * 50)
    print("âœ… All audio processing steps completed!")
    print("=" * 50)
    print("\nğŸ“ Generated files:")
    print("   Audio files:")
    print("      - sample_c_major_chord.wav")
    print("      - shifted_up_2.wav")
    print("      - shifted_down_3.wav")
    print("      - faster_1.2x.wav")
    print("      - slower_0.8x.wav")
    print("   Visualizations:")
    print("      - waveform.png")
    print("      - spectrogram.png")
    print("      - mel_spectrogram.png")
    print("      - mfcc.png")
    print("      - chroma.png")
    print("\nğŸ’¡ Next Steps:")
    print("   1. Listen to all audio files")
    print("   2. Compare visualizations")
    print("   3. Try with real jazz recordings")
    print("   4. Implement PyTorch Dataset with these features")
    print("\nğŸ· Charlie Parker Connection:")
    print("   - Mel-spectrogram: ì˜¤ë””ì˜¤ ìƒì„± ëª¨ë¸ ì…ë ¥")
    print("   - Chroma: ì½”ë“œ ì§„í–‰ ë¶„ì„")
    print("   - Pitch/Time: ë°ì´í„° ì¦ê°•ìœ¼ë¡œ 100+ ì†”ë¡œ ë§Œë“¤ê¸°")
    print()


if __name__ == "__main__":
    main()
